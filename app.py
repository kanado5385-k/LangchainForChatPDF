# -*- coding: utf-8 -*-
#from langchain.llms import OpenAI
#llm = OpenAI(openai_api_key="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")

#result = llm.predict("hi!")
#print(result)


#chat_model = ChatOpenAI(openai_api_key="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")

#result = chat_model.predict("ì•ˆë…•")
#print(result)
from langchain.chat_models import ChatOpenAI
import os
import tempfile
from loguru import logger
import streamlit as st
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain.chains import RetrievalQA

st.title("ğŸ” ChatNEWS ë‹¹ì‹ ì—ê²Œ ë‰´ìŠ¤ë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤.")
    
def pdf_to_document(pdf_file):   
    loader = PyPDFLoader(pdf_file)
    documents = loader.load_and_split()
    return documents
def main():
    pdf_folder_path = "C:\\Users\\ì •ë³´í†µì‹ ê³µí•™ê³¼\\Desktop\\ë¹…ì¹´ì¸ì¦ˆê³µëª¨ì „\\ì •í†µ\\ì½”ë“œ\\forPDF"

    pdf_files = [os.path.join(pdf_folder_path, f) for f in os.listdir(pdf_folder_path) if f.endswith('.pdf')]

    if not pdf_files:
        st.warning("PDF íŒŒì¼ì´ í´ë”ì— ì—†ìŠµë‹ˆë‹¤.")
    else:
        for pdf_file in pdf_files:
            pages = pdf_to_document(pdf_file)

            if pages:
                text_splitter = RecursiveCharacterTextSplitter(
                    separators="#",
                    chunk_size = 300,
                    chunk_overlap  = 0,
                    length_function = len,
                    is_separator_regex = False,
    )

                chunks = text_splitter.split_documents(pages)  
                #st.write(chunks)  #ì²­í¬ í™•ì¸ìœ„í•œ ì½”ë“œ streamlit run app.py

                # ì—¬ê¸°ì„œë¶€í„°ëŠ” ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                embeddings_model = OpenAIEmbeddings(openai_api_key="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")
                db = FAISS.from_documents(chunks, embeddings_model)

                st.header("PDFì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!!")
                question = st.text_input('ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”')

                if st.button('ì§ˆë¬¸í•˜ê¸°'):
                    with st.spinner('Wait for it...'):
                        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
                        qa_chain = RetrievalQA.from_chain_type(llm,retriever=db.as_retriever())
                        result = qa_chain({"query": question})
                        st.write(result["result"])
                
            else:
                st.warning(f"{pdf_file}ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()

